{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some basic stuff for analysis\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# linear algebra\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "titanic_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "### want to make sure I read the data \n",
    "#print(X)\n",
    "#read it and it was correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking test data drop\n",
      "['PassengerId' 'Pclass' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare']\n",
      "Checking titanic test data\n",
      "['Survived' 'Pclass' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare']\n"
     ]
    }
   ],
   "source": [
    "### dropping useless stuff \n",
    "#after reading it there was some useless things\n",
    "#the name does not affect the survival \n",
    "# NaN columns for cabin were a lot, pretty useless too, etc\n",
    "\n",
    "#having issues with the code below so trying to see what is going on with this line\n",
    "#print(\"TITANIC DATA COLS\")\n",
    "#print(titanic_data.columns.values)\n",
    "#print(\"TEST DATA COLS\")\n",
    "#print(test_data.columns.values)\n",
    "#OMG! THEY DONT HAVE THE SAME COLS :/ so get the same cols here lady!! \n",
    "\n",
    "#titanic_data = titanic_data.drop('Survived', axis=1)\n",
    "#I think I might need to keep passenger ID on the test set for submission lol\n",
    "test_data = test_data.drop(['Embarked','Name','Cabin'], axis=1)\n",
    "\n",
    "titanic_data = titanic_data.drop(['PassengerId','Embarked','Name','Cabin'], axis=1)\n",
    "#making sure everything that was supposed to be dropped was dropped\n",
    "print(\"Checking test data drop\")\n",
    "print(test_data.columns.values)\n",
    "print(\"Checking titanic test data\")\n",
    "print(titanic_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to use a DTC, which in this case is part of a python package lib\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay now its time for some data training in this area lol, at last\n",
    "data = [titanic_data, test_data]\n",
    "\n",
    "#filling in the gap for the age stuff since not all vals are actually filled out \n",
    "for dataset in data:\n",
    "    mean = titanic_data[\"Age\"].mean()\n",
    "    std = test_data[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = titanic_data[\"Age\"].astype(int)\n",
    "titanic_data[\"Age\"].isnull().sum()\n",
    "\n",
    "#need to recheck what is going on here lol because I have lost myself in all the data again \n",
    "#below is just to print the data info, but once needed I commented it out \n",
    "#titanic_data.info()\n",
    "\n",
    "#wow a lil probablem is that for the comparison they are not all the same types \n",
    "#aka you have comparison between floats, ints and objects lol terrible! \n",
    "#let's start by changing fare into an int! \n",
    "data = [titanic_data, test_data]\n",
    "\n",
    "#CHANGING FARE FLOAT--> INT \n",
    "for dataset in data:\n",
    "    #astype will cast into a different guy \n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "#CHANGING SEX CHAR-->BOOL, INT\n",
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [titanic_data, test_data]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)\n",
    "    \n",
    "#it says ticket is an object\n",
    "titanic_data['Ticket'].describe()\n",
    "#this one has 681 unique things, not sure what that means but I can't think of a way to convert this into just one thing\n",
    "titanic_data = titanic_data.drop(['Ticket'], axis=1)\n",
    "test_data = test_data.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking test data avail\n",
      "['PassengerId' 'Pclass' 'Sex' 'Age' 'SibSp' 'Parch' 'Fare']\n",
      "Checking titanic data avail\n",
      "['Survived' 'Pclass' 'Sex' 'Age' 'SibSp' 'Parch' 'Fare']\n"
     ]
    }
   ],
   "source": [
    "#okay so now we create the cateogies \n",
    "\n",
    "#but before I break up into cats I want to see what I still have remaining of my data lol \n",
    "#again too much data I keep forgetting what I am doing \n",
    "print(\"Checking test data avail\")\n",
    "print(test_data.columns.values)\n",
    "print(\"Checking titanic data avail\")\n",
    "print(titanic_data.columns.values)\n",
    "\n",
    "data = [titanic_data, test_data]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
    "\n",
    "# let's see how it's distributed \n",
    "titanic_data['Age'].value_counts()\n",
    "\n",
    "#same thing for fare here again\n",
    "#pretty sure I don't have to keep declaring this but whatevs \n",
    "data = [titanic_data, test_data]\n",
    "\n",
    "#now taking care of categorizing the fare!\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually doing some comparisons with the data now\n",
    "X_train = titanic_data.drop(\"Survived\", axis=1)\n",
    "Y_train = titanic_data[\"Survived\"]\n",
    "X_test  = test_data.drop(\"PassengerId\", axis=1).copy()\n",
    "#fit all this crap into the DT \n",
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(X_train, Y_train)  \n",
    "Y_pred = decision_tree.predict(X_test)  \n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported\n"
     ]
    }
   ],
   "source": [
    "#for kaggle submission\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)\n",
    "print('Exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
